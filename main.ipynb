{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import community\n",
    "import nxviz as nv\n",
    "from networkx.algorithms.community import girvan_newman, louvain_communities, louvain_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo Personagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descobrindo nomes arquivos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_path_temporadas() -> list:\n",
    "    dir_dados = 'data'\n",
    "    diretorios = os.listdir(dir_dados)\n",
    "    diretorios_temporadas = [f'{dir_dados}/{f}' for f in diretorios if os.path.isdir(f'{dir_dados}/{f}')]\n",
    "    return diretorios_temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_path_epi(path_temporada) -> list:\n",
    "    diretorios = os.listdir(path_temporada)\n",
    "    path_episodios = [f'{path_temporada}/{f}' for f in diretorios if os.path.isfile(f'{path_temporada}/{f}')]\n",
    "    return path_episodios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrair Personagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_nome_personagem(string):\n",
    "    string_upper = string.upper()\n",
    "    regex_result = re.search('^[^\"\\[]*?:', string_upper)\n",
    "    if regex_result:\n",
    "        string_personagem = regex_result.group(0)\n",
    "        if re.search('((^EXT)|(^INT))', string_upper):\n",
    "            return None\n",
    "        return regex_result\n",
    "    # return re.search('^[^\"\\[]*?:', strin_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratamento_nome_personagem(personagem_str):\n",
    "    p = re.compile('((\\(.*\\))*)(\\s?):')\n",
    "    personagem_str = p.sub('', personagem_str) \n",
    "    p = re.compile('\\s$')\n",
    "    personagem_str = p.sub('', personagem_str)\n",
    "    \n",
    "    if 'YOUNG ' in personagem_str:\n",
    "        return personagem_str.replace('YOUNG ', '')\n",
    "    elif ' VOICE' in personagem_str:\n",
    "        return personagem_str.replace('\\'S VOICE', '')    \n",
    "    \n",
    "    return personagem_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contem_digito(personagem_str):\n",
    "    return any(char.isdigit() for char in personagem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_personagens_episodio(path_arquivo, personagens, personagens_figurantes):\n",
    "    with open(path_arquivo, 'r') as file:\n",
    "        for line in file:\n",
    "            personagem = regex_nome_personagem(line)\n",
    "\n",
    "            if personagem:\n",
    "                personagem_str = tratamento_nome_personagem(personagem.group(0))\n",
    "                \n",
    "                contains_digit = any(char.isdigit() for char in personagem_str)\n",
    "                \n",
    "                if contains_digit:\n",
    "                    p = re.compile('(\\s?).(\\d)')\n",
    "                    personagem_figurante = p.sub('', personagem_str)\n",
    "                    personagens_figurantes.add(personagem_figurante)\n",
    "                else:\n",
    "                    x = re.search('((^ALL\\s)|(^ALL$)|(^AN?\\s))', personagem_str)\n",
    "                    if not x:\n",
    "                        personagens.add(personagem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personagem_invalido(personagem_str):\n",
    "    return ',' in personagem_str or '.' in personagem_str or 'CUT TO' in personagem_str or 'VOICE ' in personagem_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_personagens():\n",
    "    personagens = set()\n",
    "    \n",
    "    personagens_figurantes = set()\n",
    "    \n",
    "    for path_temporada in list_path_temporadas():\n",
    "        for path_episodio in list_path_epi(path_temporada):\n",
    "            extrair_personagens_episodio(path_episodio, personagens, personagens_figurantes)\n",
    "            \n",
    "    personagens_principais = set()\n",
    "    for personagem in personagens:\n",
    "        if personagem_invalido(personagem):\n",
    "            continue\n",
    "             \n",
    "        if personagem not in personagens_figurantes:\n",
    "            personagens_principais.add(personagem)    \n",
    "             \n",
    "    return personagens_principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "personagens = extrair_personagens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão Cenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linha_atual_dialogo(personagem_regex):\n",
    "    return False if not personagem_regex else True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personagens_na_mesma_cena(dialogos, personagens):\n",
    "    personagens_cena = set()\n",
    "    \n",
    "    for dialogo in dialogos:\n",
    "        nome_personagem = regex_nome_personagem(dialogo).group(0)\n",
    "        nome_personagem = tratamento_nome_personagem(nome_personagem)\n",
    "        \n",
    "        if personagem_invalido(nome_personagem):\n",
    "            continue\n",
    "        \n",
    "        if nome_personagem in personagens:    \n",
    "            personagens_cena.add(nome_personagem)\n",
    "        \n",
    "    return personagens_cena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nova_cena(ultima_linha_dialogo, linha_atual_contem_dialogo, dialogo_iniciado_capitulo, line):\n",
    "    if 'scene' in line:\n",
    "        return True\n",
    "    if '- - -' in line:\n",
    "        return True\n",
    "    if re.search('((^EXT)|(^INT))', line):\n",
    "        return True\n",
    "    # if re.search('^INT', line):\n",
    "    #     return True\n",
    "    # if 'EXT.' in line: \n",
    "    #     return True\n",
    "    # if 'INT.' in line:\n",
    "    #     return True\n",
    "    # if 'EXT-' in line:\n",
    "    #     return True\n",
    "    # if 'INT' in line:\n",
    "    #     return True\n",
    "    if re.search('^CUT TO', line):\n",
    "        return True\n",
    "    if not ultima_linha_dialogo and dialogo_iniciado_capitulo:\n",
    "        if linha_atual_contem_dialogo:\n",
    "            return True\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificacao_cenas(personagens):\n",
    "    personagens_cenas_serie = []\n",
    "    for path_temporada in list_path_temporadas():\n",
    "        for path_episodio in list_path_epi(path_temporada):\n",
    "            \n",
    "            with open(path_episodio, 'r') as file:\n",
    "                dialogos = []\n",
    "                ultima_linha_dialogo = False\n",
    "                gerar_quebra_cenario = False\n",
    "                dialogo_iniciado_capitulo = False\n",
    "                for line in file:\n",
    "                    \n",
    "                    if line == '\\n':\n",
    "                        continue\n",
    "                    \n",
    "                    personagem_regex = regex_nome_personagem(line)\n",
    "\n",
    "                    linha_atual_contem_dialogo = linha_atual_dialogo(personagem_regex)                   \n",
    "\n",
    "                    if personagem_regex:\n",
    "                        dialogo_iniciado_capitulo = True\n",
    "                        dialogos.append(line)\n",
    "                    elif nova_cena(ultima_linha_dialogo, linha_atual_contem_dialogo, dialogo_iniciado_capitulo, line):\n",
    "                        personagens_cena = personagens_na_mesma_cena(dialogos, personagens)\n",
    "                        if len(personagens_cena) > 1:\n",
    "                            personagens_cenas_serie.append(personagens_cena)\n",
    "                        dialogos = []\n",
    "                    \n",
    "                    ultima_linha_dialogo = linha_atual_contem_dialogo         \n",
    "                        \n",
    "    return personagens_cenas_serie                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "personagens_cenas = identificacao_cenas(personagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Conexões dos Personagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_personagens_recorrentes(personagens_cenas, frequencia_minima):\n",
    "    frequencia_personagem = {}\n",
    "    for cena in personagens_cenas:\n",
    "        for personagem in cena:\n",
    "            if personagem not in frequencia_personagem.keys():\n",
    "                frequencia_personagem[personagem] = 0\n",
    "            frequencia_personagem[personagem] += 1\n",
    "            \n",
    "    for key in frequencia_personagem.keys():\n",
    "        frequencia_personagem[key] /= len(personagens_cenas)\n",
    "            \n",
    "    personagens_recorrentes = set()\n",
    "    for personagem, frequencia in frequencia_personagem.items():\n",
    "        if frequencia >= frequencia_minima:\n",
    "            personagens_recorrentes.add(personagem)\n",
    "            \n",
    "    return personagens_recorrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados_grafo_personagens(persoangens, personagens_cenas):    \n",
    "    personagens_recorrentes = extrair_personagens_recorrentes(personagens_cenas, 0.01)\n",
    "    \n",
    "    indice_personagem = 0\n",
    "    map_personagem = {}\n",
    "    for personagem in personagens:\n",
    "        if personagem in personagens_recorrentes:\n",
    "            map_personagem[personagem] = indice_personagem\n",
    "            indice_personagem += 1\n",
    "            \n",
    "    conexoes_personagens = {}\n",
    "    \n",
    "    for personagens_cena in personagens_cenas:\n",
    "        personagens_cena_list = list(personagens_cena)\n",
    "        for i in range(0, len(personagens_cena)):\n",
    "            if personagens_cena_list[i] not in personagens_recorrentes:\n",
    "                continue\n",
    "            for j in range(i+1, len(personagens_cena)):\n",
    "                if personagens_cena_list[j] not in personagens_recorrentes:\n",
    "                    continue\n",
    "\n",
    "                personagem_1 = min(personagens_cena_list[i], personagens_cena_list[j])\n",
    "                personagem_2 = max(personagens_cena_list[i], personagens_cena_list[j])\n",
    "                \n",
    "                if personagem_1 not in conexoes_personagens.keys():\n",
    "                    conexoes_personagens[personagem_1] = {}\n",
    "                    \n",
    "                if personagem_2 not in conexoes_personagens[personagem_1].keys():\n",
    "                    conexoes_personagens[personagem_1][personagem_2] = 0\n",
    "                    \n",
    "                conexoes_personagens[personagem_1][personagem_2] += 1\n",
    "\n",
    "    conexoes = []\n",
    "    \n",
    "    for p1 in conexoes_personagens.keys():\n",
    "        if p1 == 'NAN': \n",
    "            continue\n",
    "        for p2 in conexoes_personagens[p1].keys():\n",
    "            if p2 == 'NAN': \n",
    "                continue\n",
    "            peso = conexoes_personagens[p1][p2]/len(personagens_cenas)\n",
    "            cenas = conexoes_personagens[p1][p2]\n",
    "            \n",
    "            conexoes.append({'p1': p1, 'p2': p2, 'peso': peso, 'cenas': cenas})\n",
    "\n",
    "    return pd.DataFrame.from_dict(conexoes)\n",
    "\n",
    "    # dados_grafo = {'conexoes_personagens': conexoes_personagens, 'personagens': map_personagem, 'num_cenas': len(personagens_cenas)}\n",
    "    # return dados_grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extrair_dados_grafo_personagens(personagens, personagens_cenas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "    df, source='p1', target='p2',\n",
    "    edge_attr=['peso', 'cenas']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de Centralidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralidade = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralidade = sorted(centralidade.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JON', 0.6707317073170732),\n",
       " ('ARYA', 0.6707317073170732),\n",
       " ('SANSA', 0.6585365853658537),\n",
       " ('TYRION', 0.5975609756097561),\n",
       " ('JAIME', 0.5853658536585367),\n",
       " ('DAENERYS', 0.5487804878048781),\n",
       " ('BRAN', 0.5365853658536586),\n",
       " ('CERSEI', 0.5365853658536586),\n",
       " ('JORAH', 0.524390243902439),\n",
       " ('BRIENNE', 0.5121951219512195)]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralidade[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralidade Autovetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralidade_autovetor = nx.eigenvector_centrality(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SANSA', 0.20584913079209485),\n",
       " ('ARYA', 0.2026195002009149),\n",
       " ('JON', 0.2026049164233179),\n",
       " ('TYRION', 0.19422822983564716),\n",
       " ('JAIME', 0.1869163535011763),\n",
       " ('DAENERYS', 0.18266995963261803),\n",
       " ('JORAH', 0.1789197702585332),\n",
       " ('BRAN', 0.17507487845463043),\n",
       " ('DAVOS', 0.17295956847969104),\n",
       " ('THEON', 0.1696598107877602)]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralidade_autovetor = sorted(centralidade_autovetor.items(), key=lambda x:x[1], reverse=True)\n",
    "centralidade_autovetor[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralidade Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARYA', 0.02583193813454142),\n",
       " ('JON', 0.025353922326544143),\n",
       " ('SANSA', 0.024288193800858063),\n",
       " ('TYRION', 0.021940619220889288),\n",
       " ('JAIME', 0.021936591409387973),\n",
       " ('DAENERYS', 0.020657753074910915),\n",
       " ('BRAN', 0.020148255258087642),\n",
       " ('VARYS', 0.020081277025064886),\n",
       " ('CERSEI', 0.020039980592030333),\n",
       " ('BRIENNE', 0.019798755861106427)]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank = sorted(pagerank.items(), key=lambda x:x[1], reverse=True)\n",
    "pagerank[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centralidade Proximidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralidade_proximidade = nx.closeness_centrality(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JON', 0.7522935779816514),\n",
       " ('ARYA', 0.7522935779816514),\n",
       " ('SANSA', 0.7454545454545455),\n",
       " ('TYRION', 0.7130434782608696),\n",
       " ('JAIME', 0.7068965517241379),\n",
       " ('BRAN', 0.6833333333333333),\n",
       " ('CERSEI', 0.6833333333333333),\n",
       " ('DAENERYS', 0.6833333333333333),\n",
       " ('JORAH', 0.6721311475409836),\n",
       " ('DAVOS', 0.6721311475409836)]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centralidade_proximidade = sorted(centralidade_proximidade.items(), key=lambda x:x[1], reverse=True)\n",
    "centralidade_proximidade[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de Comunidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition = community.best_partition(G, randomize=False)\n",
    "\n",
    "comunidades = louvain_communities(G, weight='peso')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comunidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(comunidades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# nx.draw(G, pos, edge_color='blue', node_color='red', with_labels=False,\n",
    "#          font_weight='light', node_size= 10, width= 0.9)\n",
    "\n",
    "# centralidade_autovetor\n",
    "\n",
    "d = nx.degree(G)\n",
    "\n",
    "node_key = [item[0] for item in centralidade_autovetor]\n",
    "\n",
    "node_values = [item[1] * 500 for item in centralidade_autovetor]\n",
    "\n",
    "peso_personagens = {}\n",
    "for item in centralidade_autovetor:\n",
    "    peso_personagens[item[0]] = item[1]\n",
    "\n",
    "colors_list = ['pink', 'green', 'blue', 'red', 'orange', 'yellow', 'brown']\n",
    "\n",
    "color_edges = []\n",
    "\n",
    "for personagem in node_key:\n",
    "    for i in range(0, len(comunidades)):\n",
    "        if personagem in comunidades[i]:\n",
    "            color_edges.append(colors_list[i])\n",
    "            break\n",
    "\n",
    "nx.draw(G, pos=pos, nodelist=node_key, node_size=node_values, edge_color='k', font_weight='light')\n",
    "\n",
    "for i in range(0, len(comunidades)):\n",
    "    node_values = [peso_personagens[personagem] * 500 for personagem in comunidades[i]]\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=comunidades[i], node_color=colors_list[i], edgecolors=colors_list[i], node_size=node_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in G.nodes():\n",
    "#     G.nodes[n][\"partition\"] = partition[n]\n",
    "#     G.nodes[n][\"degree\"] = G.degree(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition_dict = {}\n",
    "# for character, par in partition.items():\n",
    "#     if par in partition_dict:\n",
    "#         partition_dict[par].append(character)\n",
    "#     else:\n",
    "#         partition_dict[par] = [character]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_important_node_in_partition(graph, partition_dict):\n",
    "    max_d = {}\n",
    "    deg = nx.degree_centrality(graph)\n",
    "    for group in partition_dict:\n",
    "        temp = 0\n",
    "        for character in partition_dict[group]:\n",
    "            if deg[character] > temp:\n",
    "                max_d[group] = character\n",
    "                temp = deg[character]\n",
    "    return max_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[318], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmost_important_node_in_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[317], line 6\u001b[0m, in \u001b[0;36mmost_important_node_in_partition\u001b[0;34m(graph, partition_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m partition_dict:\n\u001b[1;32m      5\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m character \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpartition_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m deg[character] \u001b[38;5;241m>\u001b[39m temp:\n\u001b[1;32m      8\u001b[0m             max_d[group] \u001b[38;5;241m=\u001b[39m character\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not set"
     ]
    }
   ],
   "source": [
    "most_important_node_in_partition(G, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nv.matrix(G, group_by=\"partition\", sort_by=\"degree\", node_color_by=\"partition\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
